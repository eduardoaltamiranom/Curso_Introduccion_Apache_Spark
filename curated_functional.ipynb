{"nbformat_minor": 2, "cells": [{"source": "## 1\u00b0 PASO: Importamos m\u00f3dulos de apache spark", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *", "outputs": [], "metadata": {}}, {"source": "## 2\u00b0 PASO: Creamos las session de apache spark en una variable", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()", "outputs": [], "metadata": {}}, {"source": "## 3\u00b0 PASO: Verificamos la versi\u00f3n de apache spark", "cell_type": "markdown", "metadata": {}}, {"execution_count": 3, "cell_type": "code", "source": "spark", "outputs": [{"execution_count": 3, "output_type": "execute_result", "data": {"text/plain": "<pyspark.sql.session.SparkSession at 0x7f8c40522750>", "text/html": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://cluster-81f7-m.us-central1-b.c.weighty-works-292723.internal:4042\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.3.4</code></dd>\n              <dt>Master</dt>\n                <dd><code>yarn</code></dd>\n              <dt>AppName</dt>\n                <dd><code>PySparkShell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "}, "metadata": {}}], "metadata": {}}, {"source": "## 4\u00b0 PASO: Crear la estructura del dataframe", "cell_type": "markdown", "metadata": {}}, {"source": "## 5\u00b0 Definimos ruta del archivo", "cell_type": "markdown", "metadata": {}}, {"execution_count": 48, "cell_type": "code", "source": "ruta_lectura = \"hdfs:/datalake/landing/personas/personas.parquet\"", "outputs": [], "metadata": {}}, {"source": "## 6\u00b0 Creamos el dataframe de Persona", "cell_type": "markdown", "metadata": {}}, {"execution_count": 49, "cell_type": "code", "source": "df_with_schema_parquet = spark.read.format(\"parquet\").option(\"header\",\"true\").load(ruta_lectura)", "outputs": [], "metadata": {}}, {"source": "## 7\u00b0 Mostramos el dataframe cargado en memoria", "cell_type": "markdown", "metadata": {}}, {"execution_count": 50, "cell_type": "code", "source": "df_with_schema_parquet.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+---+---------+--------------+--------------------+-------------+----+-------+----------+\n| ID|   NOMBRE|      TELEFONO|              CORREO|FECHA_INGRESO|EDAD|SALARIO|ID_EMPRESA|\n+---+---------+--------------+--------------------+-------------+----+-------+----------+\n|  1|     Carl|1-745-633-9145|arcu.Sed.et@ante....|   2004-04-23|  32|20095.0|         5|\n|  2|Priscilla|      155-2498|Donec.egestas.Ali...|   2019-02-17|  34| 9298.0|         2|\n|  3|  Jocelyn|1-204-956-8594|amet.diam@loborti...|   2002-08-01|  27|10853.0|         3|\n|  4|    Aidan|1-719-862-9385|euismod.et.commod...|   2018-11-06|  29| 3387.0|        10|\n|  5|  Leandra|      839-8044|at@pretiumetrutru...|   2002-10-10|  41|22102.0|         1|\n|  6|     Bert|      797-4453|a.felis.ullamcorp...|   2017-04-25|  70| 7800.0|         7|\n|  7|     Mark|1-680-102-6792|Quisque.ac@placer...|   2006-04-21|  52| 8112.0|         5|\n|  8|    Jonah|      214-2975|eu.ultrices.sit@v...|   2017-10-07|  23|17040.0|         5|\n|  9|    Hanae|      935-2277|          eu@Nunc.ca|   2003-05-25|  69| 6834.0|         3|\n| 10|   Cadman|1-866-561-2701|orci.adipiscing.n...|   2001-05-19|  19| 7996.0|         7|\n| 11|  Melyssa|      596-7736|vel@vulputateposu...|   2008-10-14|  48| 4913.0|         8|\n| 12|   Tanner|1-739-776-7897|arcu.Aliquam.ultr...|   2011-05-10|  24|19943.0|         8|\n| 13|   Trevor|      512-1955|Nunc.quis.arcu@eg...|   2010-08-06|  34| 9501.0|         5|\n| 14|    Allen|      733-2795|felis.Donec@necle...|   2005-03-07|  59|16289.0|         2|\n| 15|    Wanda|      359-6973|Nam.nulla.magna@I...|   2005-08-21|  27| 1539.0|         5|\n| 16|    Alden|      341-8522|odio@morbitristiq...|   2006-12-05|  26| 3377.0|         2|\n| 17|     Omar|      720-1543|Phasellus.vitae.m...|   2014-06-24|  60| 6851.0|         6|\n| 18|     Owen|1-167-335-7541|     sociis@erat.com|   2002-04-09|  34| 4759.0|         7|\n| 19|    Laura|1-974-623-2057|    mollis@ornare.ca|   2017-03-09|  70|17403.0|         4|\n| 20|    Emery|1-672-840-0264|     at.nisi@vel.org|   2004-02-27|  24|18752.0|         9|\n+---+---------+--------------+--------------------+-------------+----+-------+----------+\nonly showing top 20 rows\n\n"}], "metadata": {}}, {"source": "## 8\u00b0 Definimos la ruta en hdfs donde almacenaremos el archivo", "cell_type": "markdown", "metadata": {}}, {"execution_count": 51, "cell_type": "code", "source": "df_nuevo = df_with_schema_parquet.withColumn('telefono', regexp_replace('telefono', '-', ''))", "outputs": [], "metadata": {}}, {"source": "## 9\u00b0 Guardamos el archivo en formato parquet", "cell_type": "markdown", "metadata": {}}, {"execution_count": 52, "cell_type": "code", "source": "df_nuevo.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+---+---------+-----------+--------------------+-------------+----+-------+----------+\n| ID|   NOMBRE|   telefono|              CORREO|FECHA_INGRESO|EDAD|SALARIO|ID_EMPRESA|\n+---+---------+-----------+--------------------+-------------+----+-------+----------+\n|  1|     Carl|17456339145|arcu.Sed.et@ante....|   2004-04-23|  32|20095.0|         5|\n|  2|Priscilla|    1552498|Donec.egestas.Ali...|   2019-02-17|  34| 9298.0|         2|\n|  3|  Jocelyn|12049568594|amet.diam@loborti...|   2002-08-01|  27|10853.0|         3|\n|  4|    Aidan|17198629385|euismod.et.commod...|   2018-11-06|  29| 3387.0|        10|\n|  5|  Leandra|    8398044|at@pretiumetrutru...|   2002-10-10|  41|22102.0|         1|\n|  6|     Bert|    7974453|a.felis.ullamcorp...|   2017-04-25|  70| 7800.0|         7|\n|  7|     Mark|16801026792|Quisque.ac@placer...|   2006-04-21|  52| 8112.0|         5|\n|  8|    Jonah|    2142975|eu.ultrices.sit@v...|   2017-10-07|  23|17040.0|         5|\n|  9|    Hanae|    9352277|          eu@Nunc.ca|   2003-05-25|  69| 6834.0|         3|\n| 10|   Cadman|18665612701|orci.adipiscing.n...|   2001-05-19|  19| 7996.0|         7|\n| 11|  Melyssa|    5967736|vel@vulputateposu...|   2008-10-14|  48| 4913.0|         8|\n| 12|   Tanner|17397767897|arcu.Aliquam.ultr...|   2011-05-10|  24|19943.0|         8|\n| 13|   Trevor|    5121955|Nunc.quis.arcu@eg...|   2010-08-06|  34| 9501.0|         5|\n| 14|    Allen|    7332795|felis.Donec@necle...|   2005-03-07|  59|16289.0|         2|\n| 15|    Wanda|    3596973|Nam.nulla.magna@I...|   2005-08-21|  27| 1539.0|         5|\n| 16|    Alden|    3418522|odio@morbitristiq...|   2006-12-05|  26| 3377.0|         2|\n| 17|     Omar|    7201543|Phasellus.vitae.m...|   2014-06-24|  60| 6851.0|         6|\n| 18|     Owen|11673357541|     sociis@erat.com|   2002-04-09|  34| 4759.0|         7|\n| 19|    Laura|19746232057|    mollis@ornare.ca|   2017-03-09|  70|17403.0|         4|\n| 20|    Emery|16728400264|     at.nisi@vel.org|   2004-02-27|  24|18752.0|         9|\n+---+---------+-----------+--------------------+-------------+----+-------+----------+\nonly showing top 20 rows\n\n"}], "metadata": {}}, {"execution_count": 53, "cell_type": "code", "source": "ruta_destino = \"hdfs:/datalake/curated/personas/personas.parquet\"\ndf_nuevo.repartition(1).write.mode(\"overwrite\").format(\"parquet\").save(ruta_destino)", "outputs": [], "metadata": {}}, {"source": "# Curated Empresa", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {}}, {"execution_count": 54, "cell_type": "code", "source": "ruta_lectura_empresa = \"hdfs:/datalake/landing/empresas/empresa.parquet\"", "outputs": [], "metadata": {}}, {"execution_count": 55, "cell_type": "code", "source": "df_with_schema_parquet2 = spark.read.format(\"parquet\").option(\"header\",\"true\").load(ruta_lectura_empresa)", "outputs": [], "metadata": {}}, {"execution_count": 56, "cell_type": "code", "source": "df_with_schema_parquet2.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+---+------------+\n| ID|EMPRESA_NAME|\n+---+------------+\n|  1|     Walmart|\n|  2|   Microsoft|\n|  3|       Apple|\n|  4|      Toyota|\n|  5|      Amazon|\n|  6|      Google|\n|  7|     Samsung|\n|  8|          HP|\n|  9|         IBM|\n| 10|        Sony|\n+---+------------+\n\n"}], "metadata": {}}, {"execution_count": 59, "cell_type": "code", "source": "df_nuevo_2 = df_with_schema_parquet2.withColumn('EMPRESA_NAME',upper(col('EMPRESA_NAME')))", "outputs": [], "metadata": {}}, {"execution_count": 60, "cell_type": "code", "source": "df_nuevo_2.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+---+------------+\n| ID|EMPRESA_NAME|\n+---+------------+\n|  1|     WALMART|\n|  2|   MICROSOFT|\n|  3|       APPLE|\n|  4|      TOYOTA|\n|  5|      AMAZON|\n|  6|      GOOGLE|\n|  7|     SAMSUNG|\n|  8|          HP|\n|  9|         IBM|\n| 10|        SONY|\n+---+------------+\n\n"}], "metadata": {}}, {"execution_count": 61, "cell_type": "code", "source": "ruta_destino_2 = \"hdfs:/datalake/curated/empresas/empresa.parquet\"\ndf_nuevo_2.repartition(1).write.mode(\"overwrite\").format(\"parquet\").save(ruta_destino_2)", "outputs": [], "metadata": {}}, {"source": "# FUNCTIONAL", "cell_type": "markdown", "metadata": {}}, {"source": "### Dataframe Personas", "cell_type": "markdown", "metadata": {}}, {"execution_count": 62, "cell_type": "code", "source": "ruta_personas = \"hdfs:/datalake/curated/personas/personas.parquet\"\ndf_personas = spark.read.format(\"parquet\").option(\"header\",\"true\").load(ruta_personas)\ndf_personas.show(5)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+---+---------+-----------+--------------------+-------------+----+-------+----------+\n| ID|   NOMBRE|   telefono|              CORREO|FECHA_INGRESO|EDAD|SALARIO|ID_EMPRESA|\n+---+---------+-----------+--------------------+-------------+----+-------+----------+\n|  1|     Carl|17456339145|arcu.Sed.et@ante....|   2004-04-23|  32|20095.0|         5|\n|  2|Priscilla|    1552498|Donec.egestas.Ali...|   2019-02-17|  34| 9298.0|         2|\n|  3|  Jocelyn|12049568594|amet.diam@loborti...|   2002-08-01|  27|10853.0|         3|\n|  4|    Aidan|17198629385|euismod.et.commod...|   2018-11-06|  29| 3387.0|        10|\n|  5|  Leandra|    8398044|at@pretiumetrutru...|   2002-10-10|  41|22102.0|         1|\n+---+---------+-----------+--------------------+-------------+----+-------+----------+\nonly showing top 5 rows\n\n"}], "metadata": {}}, {"execution_count": 63, "cell_type": "code", "source": "ruta_empresas = \"hdfs:/datalake/curated/empresas/empresa.parquet\"\ndf_empresas = spark.read.format(\"parquet\").option(\"header\",\"true\").load(ruta_empresas)\ndf_empresas.show(5)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+---+------------+\n| ID|EMPRESA_NAME|\n+---+------------+\n|  1|     WALMART|\n|  2|   MICROSOFT|\n|  3|       APPLE|\n|  4|      TOYOTA|\n|  5|      AMAZON|\n+---+------------+\nonly showing top 5 rows\n\n"}], "metadata": {}}, {"execution_count": 74, "cell_type": "code", "source": "df_personas.createOrReplaceTempView(\"tb_personas\")\ndf_empresas.createOrReplaceTempView(\"tb_empresas\")\n\ndf_sql = spark.sql(\"SELECT * FROM tb_personas p inner join tb_empresas e on e.ID = p.ID_EMPRESA\")\ndf_sql.show(5)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+---+---------+-----------+--------------------+-------------+----+-------+----------+---+------------+\n| ID|   NOMBRE|   telefono|              CORREO|FECHA_INGRESO|EDAD|SALARIO|ID_EMPRESA| ID|EMPRESA_NAME|\n+---+---------+-----------+--------------------+-------------+----+-------+----------+---+------------+\n|  1|     Carl|17456339145|arcu.Sed.et@ante....|   2004-04-23|  32|20095.0|         5|  5|      AMAZON|\n|  2|Priscilla|    1552498|Donec.egestas.Ali...|   2019-02-17|  34| 9298.0|         2|  2|   MICROSOFT|\n|  3|  Jocelyn|12049568594|amet.diam@loborti...|   2002-08-01|  27|10853.0|         3|  3|       APPLE|\n|  4|    Aidan|17198629385|euismod.et.commod...|   2018-11-06|  29| 3387.0|        10| 10|        SONY|\n|  5|  Leandra|    8398044|at@pretiumetrutru...|   2002-10-10|  41|22102.0|         1|  1|     WALMART|\n+---+---------+-----------+--------------------+-------------+----+-------+----------+---+------------+\nonly showing top 5 rows\n\n"}], "metadata": {}}, {"execution_count": 67, "cell_type": "code", "source": "df_join = df_personas.join(df_empresas, df_personas.ID_EMPRESA == df_empresas.ID)\ndf_join.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+---+---------+-----------+--------------------+-------------+----+-------+----------+---+------------+\n| ID|   NOMBRE|   telefono|              CORREO|FECHA_INGRESO|EDAD|SALARIO|ID_EMPRESA| ID|EMPRESA_NAME|\n+---+---------+-----------+--------------------+-------------+----+-------+----------+---+------------+\n|  1|     Carl|17456339145|arcu.Sed.et@ante....|   2004-04-23|  32|20095.0|         5|  5|      AMAZON|\n|  2|Priscilla|    1552498|Donec.egestas.Ali...|   2019-02-17|  34| 9298.0|         2|  2|   MICROSOFT|\n|  3|  Jocelyn|12049568594|amet.diam@loborti...|   2002-08-01|  27|10853.0|         3|  3|       APPLE|\n|  4|    Aidan|17198629385|euismod.et.commod...|   2018-11-06|  29| 3387.0|        10| 10|        SONY|\n|  5|  Leandra|    8398044|at@pretiumetrutru...|   2002-10-10|  41|22102.0|         1|  1|     WALMART|\n|  6|     Bert|    7974453|a.felis.ullamcorp...|   2017-04-25|  70| 7800.0|         7|  7|     SAMSUNG|\n|  7|     Mark|16801026792|Quisque.ac@placer...|   2006-04-21|  52| 8112.0|         5|  5|      AMAZON|\n|  8|    Jonah|    2142975|eu.ultrices.sit@v...|   2017-10-07|  23|17040.0|         5|  5|      AMAZON|\n|  9|    Hanae|    9352277|          eu@Nunc.ca|   2003-05-25|  69| 6834.0|         3|  3|       APPLE|\n| 10|   Cadman|18665612701|orci.adipiscing.n...|   2001-05-19|  19| 7996.0|         7|  7|     SAMSUNG|\n| 11|  Melyssa|    5967736|vel@vulputateposu...|   2008-10-14|  48| 4913.0|         8|  8|          HP|\n| 12|   Tanner|17397767897|arcu.Aliquam.ultr...|   2011-05-10|  24|19943.0|         8|  8|          HP|\n| 13|   Trevor|    5121955|Nunc.quis.arcu@eg...|   2010-08-06|  34| 9501.0|         5|  5|      AMAZON|\n| 14|    Allen|    7332795|felis.Donec@necle...|   2005-03-07|  59|16289.0|         2|  2|   MICROSOFT|\n| 15|    Wanda|    3596973|Nam.nulla.magna@I...|   2005-08-21|  27| 1539.0|         5|  5|      AMAZON|\n| 16|    Alden|    3418522|odio@morbitristiq...|   2006-12-05|  26| 3377.0|         2|  2|   MICROSOFT|\n| 17|     Omar|    7201543|Phasellus.vitae.m...|   2014-06-24|  60| 6851.0|         6|  6|      GOOGLE|\n| 18|     Owen|11673357541|     sociis@erat.com|   2002-04-09|  34| 4759.0|         7|  7|     SAMSUNG|\n| 19|    Laura|19746232057|    mollis@ornare.ca|   2017-03-09|  70|17403.0|         4|  4|      TOYOTA|\n| 20|    Emery|16728400264|     at.nisi@vel.org|   2004-02-27|  24|18752.0|         9|  9|         IBM|\n+---+---------+-----------+--------------------+-------------+----+-------+----------+---+------------+\nonly showing top 20 rows\n\n"}], "metadata": {}}, {"execution_count": 76, "cell_type": "code", "source": "df_select = df_join.select(col('NOMBRE'),col('EDAD'),col('SALARIO'),col('EMPRESA_NAME'))\ndf_select.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+---------+----+-------+------------+\n|   NOMBRE|EDAD|SALARIO|EMPRESA_NAME|\n+---------+----+-------+------------+\n|     Carl|  32|20095.0|      AMAZON|\n|Priscilla|  34| 9298.0|   MICROSOFT|\n|  Jocelyn|  27|10853.0|       APPLE|\n|    Aidan|  29| 3387.0|        SONY|\n|  Leandra|  41|22102.0|     WALMART|\n|     Bert|  70| 7800.0|     SAMSUNG|\n|     Mark|  52| 8112.0|      AMAZON|\n|    Jonah|  23|17040.0|      AMAZON|\n|    Hanae|  69| 6834.0|       APPLE|\n|   Cadman|  19| 7996.0|     SAMSUNG|\n|  Melyssa|  48| 4913.0|          HP|\n|   Tanner|  24|19943.0|          HP|\n|   Trevor|  34| 9501.0|      AMAZON|\n|    Allen|  59|16289.0|   MICROSOFT|\n|    Wanda|  27| 1539.0|      AMAZON|\n|    Alden|  26| 3377.0|   MICROSOFT|\n|     Omar|  60| 6851.0|      GOOGLE|\n|     Owen|  34| 4759.0|     SAMSUNG|\n|    Laura|  70|17403.0|      TOYOTA|\n|    Emery|  24|18752.0|         IBM|\n+---------+----+-------+------------+\nonly showing top 20 rows\n\n"}], "metadata": {}}, {"execution_count": 79, "cell_type": "code", "source": "ruta_functional= \"hdfs:/datalake/functional/sueldo_empleados/sueldos_empleados.parquet\"\ndf_select.repartition(1).write.mode(\"overwrite\").format(\"parquet\").save(ruta_functional)", "outputs": [{"output_type": "stream", "name": "stderr", "text": "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:39949)\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n    self.socket.connect((self.address, self.port))\n  File \"/opt/conda/anaconda/lib/python2.7/socket.py\", line 228, in meth\n    return getattr(self._sock,name)(*args)\nerror: [Errno 111] Connection refused\n"}, {"ename": "Py4JNetworkError", "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:39949)", "traceback": ["\u001b[0;31m\u001b[0m", "\u001b[0;31mPy4JNetworkError\u001b[0mTraceback (most recent call last)", "\u001b[0;32m<ipython-input-79-ba91ee38e55e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mruta_functional\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"hdfs:/datalake/functional/sueldo_empleados/sueldos_empleados.parquet\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_select\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"overwrite\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruta_functional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/dataframe.pyc\u001b[0m in \u001b[0;36mrepartition\u001b[0;34m(self, numPartitions, *cols)\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumPartitions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumPartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m                 return DataFrame(\n", "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n", "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    981\u001b[0m          \u001b[0;32mif\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \"\"\"\n\u001b[0;32m--> 983\u001b[0;31m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    935\u001b[0m         connection = GatewayConnection(\n\u001b[1;32m    936\u001b[0m             self.gateway_parameters, self.gateway_property)\n\u001b[0;32m--> 937\u001b[0;31m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0;34m\"server ({0}:{1})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_authenticate_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:39949)"], "output_type": "error"}], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark", "name": "pyspark", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.14", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}